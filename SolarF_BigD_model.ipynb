{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b02754f2-e930-45a4-8e80-18bfa7347100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch #as th\n",
    "import os\n",
    "\n",
    "import pickle\n",
    "from scipy.io import arff\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c37502cf-a263-4d13-ae09-0ad0314e6b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/fuad/Downloads/NMSU/Experiments/solar_flare'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.getcwd() #'/Users/fuad'\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "805fd81d-8adf-454b-93b1-cb2451a32311",
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder_location = path + '/Downloads/NMSU/Experiments/great_mvts/Multivariate_arff/'\n",
    "data_path = path + '/big_data_cleaned/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "82ed6299-fd19-4e67-afed-66e89ed807de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = data_path + 'partition3'\n",
    "test_data = data_path + 'partition4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cbbac4f4-3995-4b46-93bd-9f86887f720f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load(file_name):\n",
    "    with open(file_name, 'rb') as fp:\n",
    "        obj = pickle.load(fp)\n",
    "    return obj\n",
    "\n",
    "\n",
    "def load_data(partition):   \n",
    "    mvts = load(partition + \"_data.pkl\")\n",
    "    labels = load(partition + \"_labels.pkl\")   \n",
    "    return mvts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c95bd2e5-aee2-4e5b-9821-b55836de6dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binary classification --> label conversion to BINARY class\n",
    "def get_binary_labels_from(labels_str):\n",
    "    tdf = pd.DataFrame(labels_str, columns = ['labels'])\n",
    "    #data_classes= [0, 1, 2, 3]\n",
    "    #d = dict(zip(data_classes, [0, 0, 1, 1])) \n",
    "    d = {'B': 0, 'C': 0, 'F': 0, 'M': 1, 'X': 1}\n",
    "\n",
    "    arr = tdf['labels'].map(d, na_action='ignore')\n",
    "    return arr.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "91f6821f-2241-48ec-b651-c387ab846043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(X):  <class 'numpy.ndarray'>  X.shape:  (37812, 24, 60)\n",
      "type(Y):  <class 'numpy.ndarray'>  Y.shape:  (37812,)\n"
     ]
    }
   ],
   "source": [
    "X, Y = load_data(train_data)    #utils.get_XY_np_array(tarin_data[0])\n",
    "#Y = np.array(utils.get_int_labels_from_str(Y))\n",
    "Y = get_binary_labels_from(Y)\n",
    "print(\"type(X): \", type(X), \" X.shape: \",X.shape)\n",
    "print(\"type(Y): \", type(Y), \" Y.shape: \",Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cefbf75-d26d-4fbd-98a2-080ac982520f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b109072c-9aa3-445c-80c9-edf0c4fc7b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "TORCH_SEED = 0\n",
    "#building standard scaler on train data X\n",
    "\n",
    "#---------------Node Label Data Scaling-----------\n",
    "trans = utils.GetTransposed2D(X)\n",
    "data2d = utils.Make2D(trans)\n",
    "scaler = utils.GetStandardScaler(data2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ee592c22-01f2-46c4-a683-23d8df00d294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data shape: (37812, 24, 60)\n",
      "transposed data shape: (37812, 60, 24)\n",
      "2d data shape: (2268720, 24)\n",
      "mvts data shape: (37812, 60, 24)\n",
      "transBack data shape: (37812, 24, 60)\n"
     ]
    }
   ],
   "source": [
    "X_train = utils.transform_scale_data(X, scaler)\n",
    "y_train = Y\n",
    "unique_y_train, counts_y_train = np.unique(y_train, return_counts=True)\n",
    "num_y_class = unique_y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c12fbda5-1b36-466b-ac25-8f2cf7f5fe12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (37812, 24, 60)\n",
      "y_train shape:  (37812,)\n",
      "unique_y_train:  [0 1]\n",
      "y_train_counts:  [36535  1277]\n",
      "num_y_class:  2\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "#y_train_stats = dict(zip(unique_y_train, counts_y_train))\n",
    "print(\"unique_y_train: \", unique_y_train)\n",
    "print(\"y_train_counts: \", counts_y_train)\n",
    "print(\"num_y_class: \", num_y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "918a30e3-e27a-4c54-9096-2a390a20dcb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data shape: (43585, 24, 60)\n",
      "transposed data shape: (43585, 60, 24)\n",
      "2d data shape: (2615100, 24)\n",
      "mvts data shape: (43585, 60, 24)\n",
      "transBack data shape: (43585, 24, 60)\n",
      "type(X_test):  <class 'numpy.ndarray'>  X_test.shape:  (43585, 24, 60)\n",
      "type(y_test):  <class 'numpy.ndarray'>  y_test.shape:  (43585,)\n"
     ]
    }
   ],
   "source": [
    "# Test data preprocessing\n",
    "X_test, y_test = load_data(test_data)  \n",
    "#-----------------------\n",
    "X_test = utils.transform_scale_data(X_test, scaler)\n",
    "#y_test = np.array(utils.get_int_labels_from_str(y_test))\n",
    "y_test = get_binary_labels_from(y_test)\n",
    "print(\"type(X_test): \", type(X_test), \" X_test.shape: \",X_test.shape)\n",
    "print(\"type(y_test): \", type(y_test), \" y_test.shape: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "94e24113-e219-4cff-8dcd-262ae838034a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#------------------------------data crawler in train dataset\n",
    "th = [0.0, 0.1,-0.5, 0.2, 0.3, 0.4, 0.5]\n",
    "num_train = X_train.shape[0]\n",
    "num_params = X_train.shape[1]\n",
    "len_mvts = X_train.shape[2]\n",
    "#populating adjacency matrices and node attributes of train events\n",
    "train_adjs = np.zeros((num_train, num_params, num_params))\n",
    "train_nats = np.zeros((num_train, num_params, len_mvts))\n",
    "for i in range(num_train):\n",
    "  #print('Event: ', i)\n",
    "  mt = X_train[i]   #\n",
    "  #mt = normalize_node_attributes(mt)\n",
    "  train_nats[i,:,:] = mt\n",
    "  cc_mt = np.corrcoef(mt)\n",
    "  train_adjs[i,:,:] = utils.GetGraphAdjMtrx(cc_mt, [th[0]], True) #get_adj_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bd4cf376-e8e4-4f48-ac61-ef6eff0a0121",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#---------------------data crawler in test dataset\n",
    "num_test = X_test.shape[0]\n",
    "test_adjs = np.zeros((num_test, num_params, num_params))\n",
    "test_nats = np.zeros((num_test, num_params, len_mvts))\n",
    "for i in range(num_test):\n",
    "  \n",
    "  mt = X_test[i]#.T[:,0:25]\n",
    "  #mt = normalize_node_attributes(mt)\n",
    "  test_nats[i,:,:] = mt#smt.T\n",
    "  cc_mt = np.corrcoef(mt)\n",
    "  test_adjs[i,:,:] = utils.GetGraphAdjMtrx(cc_mt, [th[0]], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8690e474-ea80-47b7-aad7-6a35d5a06b21",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@title MODEL CLASS { form-width: \"10%\" }\n",
    "# (GCN) Node emb -> (mean) Graph emb -> (Flatten, Linear) -> window emb -> (LSTM) -> Temporal sequence emb -> (Linear) Class emb\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "class MVTS_GCN_RNN(torch.nn.Module):\n",
    "  def __init__(self, num_nodes, input_dims, num_temporal_split, num_sparsity_th, device, gcn_hidden_dims, node_emb_dims, graph_emb_dims, window_emb_dims, sequence_emb_dims, num_classes):\n",
    "    super(MVTS_GCN_RNN, self).__init__()\n",
    "    self.num_nodes = num_nodes\n",
    "    self.input_dims = input_dims\n",
    "    self.num_temporal_split = num_temporal_split\n",
    "    self.num_sparsity_th = num_sparsity_th\n",
    "    self.device = device\n",
    "    self.gcn_hidden_dims = gcn_hidden_dims\n",
    "    self.node_emb_dims = node_emb_dims\n",
    "    self.graph_emb_dims = graph_emb_dims\n",
    "    self.window_emb_dims = window_emb_dims\n",
    "    self.sequence_emb_dims = sequence_emb_dims\n",
    "    self.num_classes = num_classes \n",
    "\n",
    "    #self.mvts2vec = nn.LSTM(num_nodes, sequence_emb_dims)#CHANGE*******\n",
    "    self.conv1 = GCNConv(input_dims, gcn_hidden_dims)\n",
    "    self.conv2 = GCNConv(gcn_hidden_dims, node_emb_dims)\n",
    "    #self.conv2_to_class_space = nn.Linear(sequence_emb_dims+node_emb_dims, num_classes)#CHANGE*********\n",
    "    self.conv2_to_class_space = nn.Linear(num_nodes*node_emb_dims, num_classes)#--------------------------addition\n",
    "\n",
    "  def forward(self, adj_mat_array, node_att_array):\n",
    "     \n",
    "    node_att = node_att_array#----[j,:,:]#25*15\n",
    "       \n",
    "    adj_mat = adj_mat_array#[j,k,:,:]\n",
    "\n",
    "    #prepare for GCNConv\n",
    "    edge_index_tensor = utils.build_edge_index_tensor(adj_mat) \n",
    "    #edge_index_tensor, edge_weights_tensor = get_edge_index_weight_tensor(adj_mat)+++++++++\n",
    "    node_attributes_tensor = torch.from_numpy(node_att) \n",
    "    edge_index = edge_index_tensor.to(self.device)\n",
    "    #edge_weights = edge_weights_tensor.to(self.device)+++++++++\n",
    "    x = node_attributes_tensor.to(self.device)\n",
    "   \n",
    "    #GCN on the graph\n",
    "    x = self.conv1(x, edge_index) \n",
    "    #x = self.conv1(x=x, edge_index=edge_index, edge_weight=edge_weights)++++++++++++++\n",
    "       \n",
    "    x = F.relu(x)\n",
    "    #x = F.dropout(x, training=self.training)#_____________________epoch+, dropout-, regularization e-7, edge-weight\n",
    "    x = self.conv2(x, edge_index) # x.shape)#-----[25, 4]--->33x4  ++++++++++++++++++++\n",
    "    #x = self.conv2(x=x, edge_index=edge_index, edge_weight=edge_weights)\n",
    "       \n",
    "    #flattened node embeddings\n",
    "    x = x.view(1,-1) #x -> [1,x132]\n",
    "    class_space = self.conv2_to_class_space(x)#sequence2class_space(last_seq_out)#---------------------------addition\n",
    "    class_scores = F.log_softmax(class_space, dim=1) #class_space.shape)# -----------[1, 4]\n",
    "    \n",
    "    return class_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ac1fb096-9352-4728-bb75-87edf2b088f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n loss: 0 tensor(3.5657e-05, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "#TORCH_SEED = 2\n",
    "torch.manual_seed(TORCH_SEED)\n",
    "\n",
    "NUM_NODES = X_train.shape[1] #33 #25\n",
    "INPUT_DIMS = X_train.shape[2] #60 #15\n",
    "NUM_TEMPORAL_SPLIT = 4\n",
    "NUM_SPARSITY_TH = 6\n",
    "GCN_HIDDEN_DIMS = 4 #8-ok, 16-ok, 32-no \n",
    "NODE_EMB_DIMS = 4 # number of classes/can be tuned\n",
    "GRAPH_EMB_DIMS = NODE_EMB_DIMS \n",
    "WINDOW_EMB_DIMS = 64 #number of sparsity threshold/can be increased \n",
    "SEQUENCE_EMB_DIMS = 128 #4 #number of timestamps\n",
    "NUM_CLASSES = num_y_class #4\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "model = MVTS_GCN_RNN(NUM_NODES, INPUT_DIMS, NUM_TEMPORAL_SPLIT, NUM_SPARSITY_TH, device, GCN_HIDDEN_DIMS, NODE_EMB_DIMS, GRAPH_EMB_DIMS, WINDOW_EMB_DIMS, SEQUENCE_EMB_DIMS, NUM_CLASSES).to(device).double()\n",
    "loss_function = nn.NLLLoss()\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-3) #weight_decay=1e-5\n",
    "num_epochs = 1 #---------------------------------------------------\n",
    "\n",
    "#Train\n",
    "for epoch in range(num_epochs):\n",
    "  #print('Epoch: ', epoch)\n",
    "  for i in range(num_train):#num_train\n",
    "    model.zero_grad()\n",
    "    #print('Event: ', i)\n",
    "    #print (\"train_adjs n train_nats:\", train_adjs.shape, train_nats.shape)\n",
    "    adj_mat_array = train_adjs[i]#,:,:,:,:]#(4,6,25,25)\n",
    "    node_att_array = train_nats[i]#,:,:,:] #(4,25,15)\n",
    "    class_scores = model(adj_mat_array, node_att_array) \n",
    "    target = [int(y_train[i])]\n",
    "    target = torch.from_numpy(np.array(target))\n",
    "    target = target.to(device)\n",
    "    loss = loss_function(class_scores, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  if(epoch%5==0):\n",
    "    print (\"epoch n loss:\", epoch, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0e98577e-a5b0-4bba-aa46-f9b06a333e83",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def RunEpochs(num_epochs = 1, print_loss_interval = 5): \n",
    "  for epoch in range(num_epochs):\n",
    "    for i in range(num_train):#num_train\n",
    "      model.zero_grad()\n",
    "\n",
    "      class_scores = model(train_adjs[i], train_nats[i]) \n",
    "      #target = [y_train[i]]\n",
    "      target = torch.from_numpy(np.array([y_train[i]]))\n",
    "      target = target.to(device)\n",
    "      loss = loss_function(class_scores, target)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "    if(epoch % print_loss_interval == 0):\n",
    "      print (\"epoch n loss:\", epoch, loss)\n",
    "\n",
    "#------------------------------train acc\n",
    "def get_train_accuracy():\n",
    "  num_train = X_train.shape[0]\n",
    "  with torch.no_grad():\n",
    "    numCorrect = 0\n",
    "    for i in range(num_train):\n",
    "      train_class_scores = model(train_adjs[i], train_nats[i])\n",
    "      class_prediction = torch.argmax(train_class_scores, dim=-1) \n",
    "  \n",
    "      if(class_prediction == y_train[i]): \n",
    "        numCorrect = numCorrect + 1\n",
    "    return numCorrect/num_train\n",
    "\n",
    "\n",
    "#---------test acc\n",
    "def get_test_accuracy():\n",
    "  num_test = X_test.shape[0]\n",
    "  with torch.no_grad():\n",
    "    numCorrect = 0\n",
    "    for i in range(num_test):\n",
    "      test_class_scores = model(test_adjs[i], test_nats[i]) #(adj_mat_array, node_att_array)\n",
    "      class_prediction = torch.argmax(test_class_scores, dim=-1) \n",
    "      \n",
    "      if(class_prediction == y_test[i]): \n",
    "        numCorrect = numCorrect + 1\n",
    "    return numCorrect/num_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc93edf2-bfa0-4516-888c-0503d7dc15f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_accuracy():\n",
    "  print (\"train_accuracy:\", get_train_accuracy())\n",
    "  print (\"test_accuracy: \", get_test_accuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0ebdf501-c5d0-462b-b2b6-816228c062af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current epoch: 0\n",
      "train_accuracy: 0.9662276525970591\n",
      "test_accuracy:  0.9795801307789377\n",
      "current epoch:  3\n",
      "epoch n loss: 0 tensor(3.6669e-05, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Asdf\n",
    "\n",
    "TOTAL_EPOCHS = 4 #20\n",
    "EPOCH_INTERVAL = 3 #TOTAL_EPOCHS // 10\n",
    "print(\"current epoch: 0\")\n",
    "get_accuracy()\n",
    "for epoch in range(EPOCH_INTERVAL, TOTAL_EPOCHS, EPOCH_INTERVAL):\n",
    "    print(\"current epoch: \", epoch)\n",
    "    RunEpochs(num_epochs = EPOCH_INTERVAL, print_loss_interval = 300)\n",
    "    #get_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5c2adad8-f153-48cf-a06c-2927125cb03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_n_preds():\n",
    "  num_test = X_test.shape[0]\n",
    "  with torch.no_grad():\n",
    "    numCorrect = 0\n",
    "    preds = []\n",
    "    for i in range(num_test):\n",
    "      test_class_scores = model(test_adjs[i], test_nats[i]) #(adj_mat_array, node_att_array)\n",
    "      class_prediction = torch.argmax(test_class_scores, dim=-1) \n",
    "      preds.append(class_prediction)\n",
    "      if(class_prediction == y_test[i]): \n",
    "        numCorrect = numCorrect + 1\n",
    "    return numCorrect/num_test, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4cccbafa-0621-4132-ae69-ddadfa4985b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9795801307789377\n",
      "TSS:  0.0\n"
     ]
    }
   ],
   "source": [
    "#-------TSS\n",
    "from sklearn import metrics\n",
    "\n",
    "acc, y_pred = get_acc_n_preds() \n",
    "print(\"Accuracy: \", acc)\n",
    "\n",
    "TN, FP, FN, TP = metrics.confusion_matrix(y_test, list(np.concatenate(y_pred).flat)).ravel()\n",
    "tss = (TP / (TP + FN)) - (FP / (FP + TN))\n",
    "print(\"TSS: \", tss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "de4baa30-cb03-4fd0-829b-42b2b0640be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[42693,     2],\n",
       "       [  884,     6]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, list(np.concatenate(y_pred).flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1b69d666-994b-4ea8-a451-4c698cfb867f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,   172,   521,     0,     0,     0,  2875,  2446,     0,\n",
       "          14,     0,  1664, 35003,     0,     0,     0,   749,    68,\n",
       "           0,     0,     0,    73,     0,     0,     0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asdf\n",
    "\n",
    "metrics.confusion_matrix(y_test, list(np.concatenate(y_pred).flat)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "151f7af8-7357-47d1-8fdc-135442d7c169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,   172,   521,     0,     0],\n",
       "       [    0,  2875,  2446,     0,    14],\n",
       "       [    0,  1664, 35003,     0,     0],\n",
       "       [    0,   749,    68,     0,     0],\n",
       "       [    0,    73,     0,     0,     0]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, list(np.concatenate(y_pred).flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96b7d6a8-a2d4-4e65-bfd7-b6ad8b548ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8690604565790984\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rm/_51n1s5j49x0rvr3ljk1b3km0000gn/T/ipykernel_58412/3023897091.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_acc_n_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#acc = metrics.accuracy_score(y_test, y_pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mTN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mFP\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mFP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mTN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TSS: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1944e518-1075-4ffa-adf8-70ddda9a879a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_pred[0:9])\n",
    "\n",
    "yp = list(np.concatenate(y_pred).flat)\n",
    "\n",
    "yp[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "774dc812-296f-4f44-a0ef-29ba1953d815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9871c19-4a9b-4818-92ae-3ab4a6d99585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.int64'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_test[0]))\n",
    "print(type(y_pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b423998-8766-488d-9a1b-ecdac5d71e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 2]\n",
      "[tensor([2]), tensor([2]), tensor([2]), tensor([2]), tensor([2]), tensor([2]), tensor([2]), tensor([2]), tensor([2])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_test[1000:1009])\n",
    "print(y_pred[1000:1009])\n",
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "9d998651-66da-4b46-98bf-e5659bfd19af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56, 0.56, 0.58, 0.52, 0.5]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'asdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rm/_51n1s5j49x0rvr3ljk1b3km0000gn/T/ipykernel_16237/732559716.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mAccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_test_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0masdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'asdf' is not defined"
     ]
    }
   ],
   "source": [
    "Accuracy.append(get_test_accuracy())\n",
    "print(Accuracy)\n",
    "asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "ddff8942-2b90-464f-ab81-312103d5b7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56, 0.56, 0.58, 0.52, 0.5]\n",
      "p.mean(Accuracy) : 0.544\n",
      "p.std(Accuracy) : 0.029393876913398138\n",
      "p.mean np.std(Accuracy) :      0.54 +- 0.0294\n"
     ]
    }
   ],
   "source": [
    "print(Accuracy)\n",
    "print('p.mean(Accuracy) :',np.mean(Accuracy))\n",
    "print('p.std(Accuracy) :',np.std(Accuracy))\n",
    "print('p.mean np.std(Accuracy) :     ',np.round(np.mean(Accuracy),2),\"+-\",np.round(np.std(Accuracy),4) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8beff7-c7cc-4eef-a839-4c0e3b574b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy = [0.56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f51f58b-6cd8-441a-bd44-705142d7f7d4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_exp_accuracy(num_exp):\n",
    "    global model\n",
    "    global loss_function\n",
    "    global optimizer\n",
    "    \n",
    "    acc = []\n",
    "    for i in range(num_exp):\n",
    "        torch.manual_seed(i) # TORCH_SEED = i\n",
    "        loss_function = nn.NLLLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5) #weight_decay=1e-5\n",
    "        model = MVTS_GCN_RNN(NUM_NODES, INPUT_DIMS, NUM_TEMPORAL_SPLIT, NUM_SPARSITY_TH, device, GCN_HIDDEN_DIMS, NODE_EMB_DIMS, GRAPH_EMB_DIMS, WINDOW_EMB_DIMS, SEQUENCE_EMB_DIMS, NUM_CLASSES).to(device).double()\n",
    "\n",
    "        for epoch in range(EPOCH_INTERVAL, TOTAL_EPOCHS, EPOCH_INTERVAL):\n",
    "            print(\"Exp no. {}, epoch: {}\".format(i, epoch))\n",
    "            RunEpochs(num_epochs = EPOCH_INTERVAL, print_loss_interval = 300)\n",
    "            get_accuracy()\n",
    "        acc.append(get_test_accuracy())\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552a97a6-0f2d-4ddb-8ddf-eedcef63e495",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy = get_exp_accuracy(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e9c6a8-a772-41a1-b27c-46e4541cb83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RunEpochs(num_epochs = 20, print_loss_interval = 2)\n",
    "#get_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6be6594-6f88-40b8-ab2b-ed7305f0bc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d40278-c0b1-42a9-8ba1-f792ffca898e",
   "metadata": {},
   "source": [
    "#As"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da9b480-20ad-4382-b2c9-56b59781f795",
   "metadata": {},
   "source": [
    "**ASD**\n",
    "\n",
    "asdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4482ce-5958-4995-8c95-257d94eaa938",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
